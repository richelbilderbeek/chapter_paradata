\setcounter{chapter}{7}
\chapter{Research code is paradata and as vital as the article itself}

\abstract{

Here we define paradata as data about the data collection process.
Computer code is the paradata for a computatioal/academic experiment,
allowing the experiment to be reproduced.
However, code is published alongside an academic
paper in a minority of all cases.
As reproducibility is a cornerstone of science,
research code should be published.
Earlier general recommendations about making paradata (more) useful
is tailored to code, using the field of genetic epidemiology
as an example.
The chapter concludes by some rules how to better code to serve as paradata,
and hence allowing computational research to be truly reproducible.

} % abstract

{\bf Keywords:} paradata, reproducible research, code, software,
FAIR data, computational research, Open Science, best practices,
genetic epidemiology

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Definitions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{table}[h]
  \begin{tabular}{lp{5cm}p{5cm}}
    Term      & Definition                                            & Example                                                         \\
    \hline
    Code      & Body of text to be run by a computer                  & The scripts run by a computational experiment                   \\
    Data      & Individual facts, statistics, or items of information & A SNP that has a significant association                        \\
    Genotype  & The DNA allele at a certain location                  & AA, AC, CG, GT, ...                                             \\
    Paradata  & Data that describe the process of generating data     & The code to conclude that a SNP has a significant association   \\
    Phenotype & How an organism looks like in the broadest sense      & The concentration of IL6RA in the blood                         \\
    Primary data & Data that are worked with in a research            & The genotype of individuals   \\
    Metadata  & Data that provide information about other data        & The article that describes an experiment                        \\
    Raw data  & Data directly from the real world, that are not yet ready to be primary data & The raw results of getting the genotypes of individuals   \\
    Trait     & A phenotype                                           & The concentration of IL6RA in the blood                         
  \end{tabular}
  \caption{Terms used in this paper, and their definitions}
  \label{tab:definitions}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\epigraph{
  Talk is cheap. Show me the code.
}{
  Linus Torvalds, 2000-08-25
}

% This section has paragraph headers. This helps me, the author,
% to focus the contents of my paragraphs.
% In the final version of this manuscript, these will be removed.

% \paragraph{Simple example}

% Alex and Blake?
Two different researchers in genetic epideomology (more on that field later), 
write two equally good manuscripts
that involve computation.
Both manuscripts are accepted by an equally prestigous journal after peer view. 
One researcher, however, does not supply the
computer code (from now on: 'code') that was used to generate the results,
where the other does.
Are the conclusion of these papers to be trusted equally?
Is this difference relevant and worth the effort?
This chapter discusses the effect of supplying the computer 
code  
and claims that code is paradata and that this paradata 
is just as important as the paper itself.

% \paragraph{The first definition paradata}

The concept of paradata (although not named as such yet) 
was introduced by \cite{couper1998measuring},
who developed a computer-assisted interview program
that, among others, records all key strokes,
measures the time used to answer each question 
and even the time the monitor is turned off.
The goal in that context was to assess and improve survey quality.

% \paragraph{Definition of paradata}

This paper defines paradata as 'data about the data collection 
process' \cite{choumert2019using}.
This definition is chosen for its simplicity, 
yet there are multiple related and/or more nuanced 
definitions of paradata (see for example \cite{huvila2022improving} 
and \cite{skold2022interrogating}).

% Code is paradata

The code used in experiments is just that, 'data about the data collection 
process', as it commonly downloads data, selects relevant subsets in those
downloaded data and performs statistical tests to generate results.
Code, hence, is paradata and this chapter explores and illustrates the
consequence of that premise.

% \paragraph{Modern forms of paradata}

A recent paper explores the use of paradata to increase the impact of data,
stating that lack of paradata can be seen as 'a drastic constraint'
in the use of data and offer some suggestions to 
make paradata useful for data re(use):
paradata should be comprehensive, comprehensively documented
and friendly to computers \cite{huvila2022improving}.
These suggestions appear to work with code as well,
where these suggestions show up as best practices (such
as \cite{stodden2013best}), some of which
described below.
The lack of computer code is just as much 'a drastic constraint'
in the use of a (computational) scientific experiment.
The clearest effect of its absence is, most obviously,
that a computational experiment cannot be redone 
easily, yet there are wider implications, described below, as well.

% \paragraph{This paper is about computer code}

This paper is about paradata in the context of a computational
experiment in general and uses an example from genetic 
epidemiology in particular.
It is argued that code, being paradata, is as vital as the academic
paper itself, illustrated by the two scientists at the start of 
this chapter. After that, the implications and recommendations
follow.

\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{figure_1.png}
  \caption{
    Left: general relation between data, paradata and metadata.
    Middle: the same relations specified for eBird.
    Right: the same relations specified for genetic epidemiology.
  }
  \label{fig:figure_1}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Genetic epidemiology}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \paragraph{Introduction}

This paper uses genetic epidemiology as a specific example,
to illustrate that the code is paradata,
that this type of paradata is relevant, as it helps 
to assess the correctness of the results,
where the correctness of the results is relevant for 
science in general and healthcare in particular.
However, any field that uses computation in its experiments
could be used as an example.

% \paragraph{Publication of code}

Going back to the example scientists in the introduction,
where one does and the other does not publish the code,
it is not common to publish the code of an experiment or analysis 
\cite{stodden2011trust,read2015sizing} (with a pleasant exception 
being \cite{conesa2019making}).
For example, in computer graphics, 
a field intimately familiar with computer code,
only 192 of 454 SIGGRAPH papers supply computer code \cite{bonneel2020code}.
Another study analysed the reproducibility of registered reports
in the field of psychology, 
where still only 37 out of 62 studies supplied the code 
to redo the analysis \cite{obels2020analysis}.

% \paragraph{For some fields, the experiment is actually run by code}

Genetic epidemiology is a field within biology that, among 
others, measures the spread of heritable traits,
as well as how these come to be.
For example, we know that lactose intolerance in adults is
caused by a decline in the production of lactose-degrading enzymes,
and is most commonly found in south-east asia and south africa \cite{storhaug2017country}.
The trait is caused by the genetic make-up, 
or genotype 
(see Table \ref{tab:definitions} for the definitions of terms used in this paper), 
of a person.
The trait, also called phenotype (again, see Table \ref{tab:definitions}), 
in this example is lactose intolerance at adult age,
yet any human property, such as weight or height can be studied.
Genetic epidemiology studies the spread of genotypes and phenotypes,
as well as the relation between those two.
When an association between genotype and phenotype is found,
these associations are subsequently used to 
create gene panels, where the gene causing 
an association is measured specifically, to, among others,
detect people at risk for the associated phenotype.

The rest of this section describes a genetic epidemiology study 
in more detail, with special focus on the computational experiment.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{Karesuando_church.jpg}
  \caption{
    Picture of Karesuando's church,
    the village where the Northern Swedish Population
    Health Study started.
    From \cite{hopfner2005}
  }
  \label{fig:karesuando_church}
\end{figure}
\fi

The example study followed is a pseudorandomly selected paper
from \cite{ahsan2017relative}. The primary data used by that paper is
from a population study called the Northern Swedish Population
Health Study (NSPHS) that started in 2010 \cite{igl2010northern}. 
The approximately 1000 participants were initially mostly surveyed
about lifestyle \cite{igl2010northern} and follow-up studies
provided the type of data relevant for this paper, 
which are (1) the genotypes \cite{johansson2013identification},
(2) the phenotypes, in this case, concentrations of certain proteins in the 
blood \cite{enroth2014strong,enroth2015effect}.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{1189px-Eukaryote_DNA-en.png}
  \caption{
    A cell has a nucleus that contains chromosomes. 
    Each of these chromosomes (46 in humans) consist out of DNA. 
    DNA itself conists out of 4 nucleotides, 
    as depicted by the horizontal sticks 
    with the colors red, yellow, green and blue.
    From \cite{sponk2012}
  }
  \label{fig:eukakyote_dna}
\end{figure}
\fi

The first type of primary data, the genotypes, 
consists out of single nucleotide polymorphisms (SNPs, pronounced as 'snips').
A SNP has a name and a location on the DNA, at which there is a certain nucleotide.
DNA (organized into chromosomes and present in every (nucleated) cell, 
\iffalse
(see figure \ref{fig:eukakyote_dna}))
\fi
consists out of billions of nucleotides.
There are four types of nucleotides, 
called adenosine, cytosine, guanine and thyrosine, all commonly abreviated
as A, C, G and T respectively.
One SNP example is \verb|rs12133641|, which is a SNP located at position 
154,428,283, where 67 percent of the people within this study have an A,
and 33 percent have a G (also from \cite{ahsan2017relative}, Table S3).

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{DNA_to_protein.png}
  \caption{
    Parts of DNA (so-called 'genes') code for proteins. 
    The DNA, that always stays put in the cell's nucleus, 
    is transcripted to messenger RNA (mRNA).
    mRNA leaves the nucleus and its code gets translated to 
    a protein sequence.
    Near the start of a gene are regions that determine the amount
    of proteins produced (not shown in figure).
    Adapted from \cite{shafee2015}
  }
  \label{fig:dna_to_protein}
\end{figure}
\fi

The second type of data, the phenotypes, 
are concentrations of proteins in the blood. 
DNA contains the code for building proteins
\iffalse
(see Figure \ref{fig:dna_to_protein})
\fi
, as well as the rate
at which a protein is created. Some proteins end up in the blood and
their presence can be used to assess the health of an individual.
IL6RA is one such protein and, spoiler alert, its concentration
is associated with the SNP mentioned earlier.

The field of genetic epidemiology looks -among others- for
correlations between genetic data and biological traits.
For example, \cite{ahsan2017relative} shows that
SNP \verb|rs12133641| is highly correlated (p-value is $3.0^{-73}$
\iffalse
(see figure \ref{fig:ahsan2017relative_table_2_sub})
\fi
,
for $n$ = 961 individuals) with protein IL6RA.
The direction of the association is also concluded:
the more guanines (as opposited to adenines) are present at that SNPs location,
the higher concentration of IL6RA can be found in a human's blood
\iffalse
(see figure \ref{fig:ahsan2017relative_table_2_sub})
\fi
. The amount of variance that can be explained by an association (i.e.
the R squared value) is rarely 100 percent, which means that a trait (in
this case, the concentration of IL6RA) cannot be perfectly explained
from the genotype (in this case, SNP \verb|rs12133641|) alone. 
In this example, 43 percent of the variance 
can be attributed to an individuals' genotype
\iffalse
(see figure \ref{fig:ahsan2017relative_table_2_sub})
\fi
. Additional factors, 
such as the effect
of the environment (e.g. geographic location, time of day), 
lifestyle (e.g. smoking yes/no) or having a disease (e.g. diabetes) 
are needed to explain the additional variation.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{ahsan2017relative_table_2_sub.png}
  \caption{
    An example result of a genetic epideological research.
    It shows that the SNP named rs12133641 (located at position 154,428,283
    of chromosome 1) is highly correlated (p value is 3.0 * 10e-73, 
    961 individuals) to the concentration of the protein IL6RA, as measured
    in blood. The table is a simplified result from \cite{ahsan2017relative}.
  }
  \label{fig:ahsan2017relative_table_2_sub}
\end{figure}
\fi

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{ahsan2017relative_s6.png}
  \caption{
    The relation between the genotype for SNP rs12133641 
    and the protein concentration of IL6RA is relatively strong.
    The X axis shows the the genotype of the individuals,
    where 0 denotes AA, 1.0 denotes AG and 2.0 denotes GG.
    The Y axis shows the concentration of the protein IL6RA 
    as found in the participants' blood. n = 1 denotes the number
    of SNPs that were determined to be involved.
  }
  \label{fig:ahsan2017relative_s6}
\end{figure}
\fi

The conclusions drawn from this paper,
may end up in the clinic.
For the sake of having a clear (yet fictitious) example,
let's assume that a high level of IL6RA 
is associated with a disease that develops later in life,
yet is preventable by lifestyle changes.
Would this be the case, we can create a tailored 
experiment, called a gene panel, that specifically measures
SNP \verb|rs12133641|. 
If the gene panel shows an individual has two guanines, 
we know that this person is likelier to develop higher levels of
IL6RA and is likelier to benefit from the lifestyle changes.

From this simple example, it will be easier
to measure the level of IL6RA in the blood, than using a gene panel,
as blood tests are easier and cheaper.
However, there are associations published for many diseases,
in which one (e.g. phenylketonuria) or many (e.g. \cite{bruce2009metabolic}) 
SNPs contribute to being more likely to develope a disease in the future. 
Here, the phenotype (having a disease in the future) 
is impossible to detect at the present
and associations found in earlier studies are used to create a gene panel.
As creating a gene panel is costly, those associations better be correct.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Code is just as important as the paper}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \paragraph{The experiments within genetic epidemology works are done by code}

The experiment described above is run by code. 
It was code that detected the relationship between the genotype
(in this case, SNP \verb|rs12133641|) 
and the phenotype (in this case, the concentration of IL6RA).

The code for this experiment is vital paradata.
Like all paradata, its omission would be a constraint in the
use of the conclusion reached by it:
we can use it to assess the trustworthiness of the finding,
for example, by running the code again.
Ideally, the code is comprehensive, comprehensively documented
and be friendly to computers \cite{huvila2022improving}.
Code being friendly to computer seems like an obvious 'yes',
yet this is naive, as commonly it is hard to run code in practice. 
% TODO: Link to correct paragraphs
For code to be called computer-friendly, it must be run on an independent entity, 
as is discussed in the paragraphs about hosting code and/or putting the code in a container.
% TODO: Link to correct paragraphs
Also note that there is a problem due to the inherent sensitivity of the genetic data,
which is discussed in paragraph.
Lastly, note that the researcher used data that was itself generated by code:
complex bioinformatics pipelines are used to obtain reliable DNA sequences 
from the biological sample.

% \paragraph{Science should be reproducible}

A scientific claim must be reproducible before it is accepted
by the scientific community.
Reproducibility (i.e. to reproduce the same results) 
and replicability (i.e. to reconclude a conclusion)
are fundamental characteristics of scientific studies \cite{patil2019visual}.
For computational science, theoretically, it should be relatively easy to 
reproduce an experiment, as all it takes is a computer, electricity,
an optional internet connection, the code and the data.
In practice, however, it appears that 
the academic culture to reproduce results 
has been lost over time in general \cite{peng2011reproducible},
with labs that embrace reproducibility (for example, \cite{barba2016hard})
are the exception.

That same study recommended, as a solution to counter this, 
to make reproducible research a minimal requirement for 
publication \cite{peng2011reproducible}.

% \paragraph{Code should be published}

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{peng2011reproducible_fig_1.png}
  \caption{
    Levels of reproducibility, from \cite{peng2011reproducible}
  }
  \label{fig:peng2011reproducible}
\end{figure}
\fi

The code of a computational experiment must be published
for an experiment to be easily reproducible.
It is however (too) common that the original data
and/or code are unavailable \cite{peng2021reproducible}.
One saddening example is described in \cite{haibe2020importance}, where
an algorithm that detects breast cancer from images better than a human expert,
was irreproducible.
In the case of genetic epidemiology, 
the original data usually cannot be published, 
due to the guaranteed privacy of the people having shared their characteristics.
The code of a computational experiment, however, \emph{can} be
distributed without such problems.
In academic journals, however, its is not code that is published, 
but an English description of what it does instead.

% \paragraph{Example of code being the ground truth}

From a broader perspective, code should be published, as it holds the
ground truth of an experiment; it does the actual work.
The more complex the computation pipeline is, the easier it is
to have a mismatch between the article (that describes what the
code does) and the code (that actually does the work).
It is easy (tempting?) to overlook how easy it is to have a mismatch
between paper and code.

To illustrate how easy it is to get a mismatch between a paper
and the code, 
consider this example of a possible text in the fictional 
genetic epidemiology paper:

\begin{verbatim}
We compared the in-blood concentrations of IL6RA 
between subjects having AA versus subjects having GG at SNP rs12133641,
using an unpaired one-tailed T-test,
as we expect the average concentration of IL6RA for those with AA 
to be less than the average concentration in those with GG.
\end{verbatim}

We ignore the choices of words and style of this sentence: what is
important is the content: an unpaired one-tailed T test is performed.
Taking a look at the (in this case, the programming language R) code, 
we find the following line:

\begin{verbatim}
t_test_result <- t.test(subjects_with_aa, subjects_with_gg)
\end{verbatim}

The code is correct:
\verb|t.test| is indeed the name of an R function to do an unpaired T-test
and it is reasonable to assume that this code, when glancing over the code
of an article, is correct.

Here, however, we see a mismatch between the English description and the code:
by default, the R function \verb|t.test| does 
a \textbf{two}-tailed unpaired T-test.
A consequence of this fictional example is that the published p-values are
higher than needed, resulting in less significant findings, which
results in (needlessly) less conclusions drawn in this fictional paper.

Note that there is another side of this same coin:
correctly reporting the T-test in a reproducable ways
is known to be a problem, with only 80 out of a selected 179 papers
fully reporting the parity of T-test (i.e. paired or unpaired) 
\cite{weissgerber2018we}.
In those unresolved 99 papers, 
the code (if published) would clarify this.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{baggerly2009deriving_fig_1a.png}
  \caption{
    Gene expression result due to an off-by-one error.
    The cells in the main table show how much mRNA is produced per cell 
    line (the columns) for different proteins (the rows).
    The colors above the cells, with the dendrogram, shows
    red for cells that do not respond (red) and do respond (blue) to an 
    antibiotic.
    The purple rectangles show samples that are duplicated.
    Note that, due to this, some
    samples that behave identically are both non-responders and responders.
    From \cite{baggerly2009deriving}
  }
  \label{fig:baggerly2009deriving}
\end{figure}
\fi

It is the paper that accompanies the code,
as it is the code that generates the results.
When humans are fallible and code gets bigger, the likelihood of
a mismatch between the English paper and the code increases.
We know that the most common errors are 
simple (and may legitimately fear that those simple errors are common) 
\cite{baggerly2009deriving},
and this example is not too far off from the
examples given in that paper.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Making code useful paradata}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Again, paradata should be comprehensive, comprehensively documented
and friendly to computers \cite{huvila2022improving}.
In this section, these ideal properties of paradata are applied to code.
The resulting recommendations are compared with
existing best practices in writing code.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Code must be extensively documented}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For code to be ideal paradata, it must be documented.
However, code does explain itself to some extent,
for example, the function name \verb|t.test| as used above.

\begin{itemize}
  \item Code must be documented to the right amount
  \item Code must be reviewed
\end{itemize}

\paragraph{Code must be documented to the right amount}

Code should be documented to the right amount:
too little documentation is unhelpful, where too much is a needless burden
on the programmer.
The first recommended practice is to write the code in such a way 
that it becomes self-explanatory \cite{wilson2014best}.
What is left to document are the reasons behind the code, 
its design and its purpose \cite{wilson2014best}.

\paragraph{Code must be reviewed}

As it is the code that is the most important actor in an the experiment,
it should be treated as equally or more important than the scientific
paper describing what is does.
Regardless of this, most academic journals, 
when concerning computational experiments
only review the (usually) English description of the code
and make the review of code optional.
One notable exception is rOpenSci \cite{ram2018community},
which is an organisation that does peer-review academic code 
and facilitates the optional publication of a paper.
Although both code and paper are peer-reviewed,
most effort is spent on reviewing the code,
as can be seen in, for example, 
the \verb|mcbette| R package \cite{bilderbeek2020mcbette}.
Within software development best-practices, 
code reviews are recommended as well \cite{wilson2014best} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Code must be extensive}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For code to be ideal paradata, it must be extensive.
As code has many properties, there are many recommendations on this aspect.

\begin{itemize}
  \item Code must be clean
  \item Code must be hosted
  \begin{itemize}
    \item Hosted code generated important metadata
    \item Code must be tested
    \item ...
  \end{itemize}
  \item Code must be tested
  \begin{itemize}
    \item ...
  \end{itemize}
\end{itemize}


\paragraph{Code must be clean}

Raw code gives an indication of the quality 
of a computational experiment and several metrics are
devised to get an idea of the quality of code.

The simplest metric to assess the quality of code is 
the amount of (single) lines of code (SLOC). 
Code that has a lower SLOC count, i.e. it is more concise,
is usually regarded as having a lower chance of containing bugs.
Additionally, following a style guide 
(e.g. the Tidyverse style guide \cite{wickham2019advanced} for R,
or PEP 8 \cite{van2001pep} for Python), 
improves software quality \cite{fang2001}.

A more interesting metric is the cyclomatic complexity of the code.
The cyclomatic complexity is approximately defined 
as the number of independent paths that
the code can be executed. 
For example, code that has only one \verb|if| statement
has a cyclomatic complexity of 2, as the condition within the \verb|if|
statement can be true or false,
resulting in the body of the \verb|if| statement being either
exectuted or ignored.
The cyclomatic complexity correlates with code complexity,
where more complex code is likelier to contain or give rise to bugs 
\cite{abd2018calculating,chen2019empirical,zimmermann2008predicting}

A feature that deserves more attention
is that 'code must act as a teacher for future developers' \cite{sadowski2018modern}.
Error handling is one of the mechanisms to do so.
A simple example is when one (e.g. a BSc student) 
needs to calculate the variance of a distribution.
Commonly one needs to call a function to do so, 
e.g. \verb|var| in R, that needs the values of the distribution
as input.
However, to calculate the variance of a distribution, at least two values
are required (else a division by zero occurs in the calcation of the variance). 
When the variance of (zero or) only one value is requested,
an error message can helpfully indicate that the function 
needs at least two values to work as expected.

\paragraph{Code must be hosted}

% \paragraph{Code must be hosted to be moderately computer-friendly}
Code is sometimes published alongside a paper, 
in the form of a code hosting website.
This way of publishing code gives additional options,
both for the authors of that code, as well as its users.
This practice has increased,
with the abstracts from articles in the academic journal
'Bioinformatics' referring to such a hosted website
has increased tenfold, going from below 5 percent in 2009 
to around 50 percent in 2017 \cite{russell2018large}.

\paragraph{Example of hosted code}

There are multiple websites for hosting code, with BitBucket, GitHub,
GitLab and SourceForge being the most well-known.
GitHub is currenly the most popular website to host code in general,
with millions of users (a simple user search can confirm this).
GitHub users can create dedicated websites (called 'repositories')
to upload code. Code hosts, such as GitHub, 
store that uploaded code and provide ways 
for visiters to download the code and/or interact with it.
The use of such code hosting websites
accommodates collaboration \cite{perez2016ten}.
and improves transparency \cite{gorgolewski2016practical}.
An example from the author is the website \cite{bbbqarticleissue157},
that hosts part of the code for the paper \cite{bilderbeek2022transmembrane}
\iffalse
, as shown in Figure \ref{fig:bbbqarticleissue157}
\fi
.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{bbbq_article_issue_157.png}
  \caption{
    A typical GitHub repository \cite{bbbqarticleissue157}, 
    hosting the code for a
    computational experiment, 
    as published with \cite{bilderbeek2022transmembrane}.
    Note that this repository has 72 commits, where a commit is a change
    to the code.
  }
  \label{fig:bbbqarticleissue157}
\end{figure}
\fi

\paragraph{Hosted code has important metadata}

Hosted code has many additional features, such as
a version-controlled history, continuous integration scripts
and automatically generated metrics.
A code hosting website produces and shares these metadata.
These metadata can help to determine the
reproducibility, correctness and quality of code
of computational experiments.
Below, those features and why these are important are discussed.

\paragraph{Hosted code keeps a history of changes}

Hosted code commonly has a commit history. For example, GitHub
uses a version control system called \verb|git| (hence its name).
In practice, this means that when a change is made to the code,
a new version is created. In the case that the change was harmful,
one can go back to an earlier version and continue again from there.
It is a general recommendation to put version control
on all human-produced data \cite{wilson2014best}.

\paragraph{A commit history helps assess honest reporting}

Hosted code improves transparency \cite{gorgolewski2016practical},
as, among others, the history of changes (i.e. the git commit history), 
helps to assess the honesty in the reporting of the code. 
Ideally, the full version history of the code 
has been generated, by hosting the code directly at its inception,
so that the ontology of the experiment can be viewed.
However, in some repositories, only the final version of the code has been
posted, which means all historical information is lost.
The code history has many important properties,
as, for example, 
it can be observed how much statistical tests have really/actually been done 
and see if all are reported:
failing to reporting a (usually non-significant) statistical tests is 
one of the many degrees of freedom 
in p-value hacking \cite{wicherts2016degrees}.

\paragraph{Code must be tested}

\paragraph{Continuous integration helps assess code quality}

Some code hosts, among others, GitHub, 
allow the researcher/user to start software scripts upon uploading a change.
This is useful to determine the reproducibility of the code: 
one such script should run the code (on trivial data) 
to verify if the code works at all.
If the functionality of the code is lost, the researcher
can immediatly see which small change was the cause of this.
A formalized version of this workflow is called continuous integration (CI).
Using a CI service (such as GitHub Actions for GitHub), 
is known to significantly 
increase the number of bugs exposed \cite{vasilescu2015} and increases
the speed at which new features are added \cite{vasilescu2015}.
Using CI opens up the possibility to informally annotate features of
a repository. 
\iffalse
For example, Figure \ref{fig:build_badge} shows a 
build badge that indicates that a \LaTeX document (i.e. this paper)
could be built.
\fi

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{build_badge.png}
  \caption{
    A build badge for the GitHub repository of this article.
    The description indicates which process it is that the badge
    signals success (as in this case) or failure of. 
  }
  \label{fig:build_badge}
\end{figure}
\fi

% \paragraph{Code coverage helps assess code quality}

Testing, in general, is an important mechanism to ensure
the correctness of code (an interesting example is \cite{rahman2020exploratory}
showing bugs in scientific software on the COVID-19 pandemic:
it recommends more testing).
The percentage of (lines of) code tested is called the code coverage.
Code coverage correlates with code quality \cite{horgan1994,del1995correlation}. 
The non-profit organisation rOpenSci \cite{ram2018community},
which peer-reviews code,
has made it a prerequisite to have a code coverage of 100\%.
Also here, CI opens up the possibility to informally annotate the
code coverage. 
For example, build badges
\iffalse
(e.g. as shown in Figure \ref{fig:badge_codecov})
\fi
are visual indications on a website that can, among others,
show a certain R package's code has a 100\% code coverage.

Hence, code coverage is important metadata, that can automatically
be acquired when using code hosting website.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[]{badge_codecov.png}
  \caption{
    A build badge for the code coverage of an R 
    package (\url{https://github.com/ropensci/beautier}).
    The umbrella signals that the code coverage is hosted by
    CodeCov (\url{https://codecov.io/}). 
    The text indicates which process it is that the badge
    signals, which in this case, is that the code is fully covered
    by tests.
  }
  \label{fig:badge_codecov}
\end{figure}
\fi

% \paragraph{Metrics help assess the honest division of labour}

Most code hosts, among others, GitHub and GitLab,
automatically keep track of certain metrics.
One such metric is the amount of code each contributor has made.
In that way, authors involved in the writing of the software
are honestly acknowledged. 
\iffalse
Figure \ref{fig:daisie_contributors}
shows the number of commits the authors of DAISIE \cite{etienne2020daisie}
have made to its code.
\fi
The distribution of contributed code per author 
is useful metadata, that can automatically
be acquired when using code hosting website.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{daisie_contributors.png}
  \caption{
    An overview of the commits that multiple contributors have
    made, in this case, to the code of DAISIE \cite{etienne2020daisie}
  }
  \label{fig:daisie_contributors}
\end{figure}
\fi

% \paragraph{A reader can contact the author}

A feature that gets too few attention is that code hosts
allow users to post bug reports and/or ask questions.
This allows other researchers to assess the health
of the code.
A healthy project has few open bug reports
and these bug reports should be closed within reasonable time.
When bug reports start to accumulate, this
signals either that the code contained many bugs or that
the developers lost interest in maintaining that code.
The amount of bug reports is useful metadata, 
especially when deciding to use (and depend) on a piece of software.

\iffalse
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=\linewidth]{issue_ldpred2.png}
  \caption{
    An overview of the issues for the code for
    LDpred2 \cite{prive2020ldpred2}. Of the 310 issues, 300 have been closed.
    The first four issues have been replied to, as indicated by the
    talk balloon. The fifth issues has a label with the text 'feature request'
    to signal the issue type.
  }
  \label{fig:issue_ldpred2}
\end{figure}
\fi


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Code must be computer friendly}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

There are multiple ways of publishing code,
that require increasingly more knowledge to do and result
in increasingly more reproducible experiments:
(1) publishing the code as text only, e.g. by printing
it in a Supplementary Materials, (2) publishing
the code on a hosted website, e.g on GitHub, with
added features (3) publishing 
the installed code within a virtual environment,
for example, using a Singularity container.
In this chapter, details of each of these ways will be described,
including advantages, disadvantages, as well as how to
make the code more FAIR data \cite{wilkinson2016fair}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Publishing raw code}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \paragraph{The problems with hosted code}

Albeit hosted code is vastly superior over raw code
in case of reproduciblity and correctness,
there are some problems with hosted code as well.
The most important one is that hosted code needs maintanance:
the libraries that are used by an experiment
will change over time, inevitably causing the experiment to fail
over time. 
The degradation of software is a known feature for nearly 
four decades (see the definition of 'bit rot' at \cite{steele1983hacker}),
here a more modern (and in this context superior)
definition is used: software collapse \cite{hinsen2019dealing},
in which software fails due to dependencies on other 
software.
Where that paper recommends using older software foundations 
with multiple implementations \cite{hinsen2019dealing},
this paper recommends a modern solution that potentially has more longevity:
to publish the code installed in a virtual environment
(including the dependencies used at that time), as described below.

There is another problem that authors of academic code face,
which is that they may be contacted with a user 
asking for technical report 
(against which a 'no' is just fine \cite{barnes2010publish})
or -more relevant to the research- sending in a bug report.
One solution for the author is to ignore such emails
and it can be argued that no energy should be wasted on published code
and work on something new instead 
(see \cite{barnes2010publish} for a better way to deal with the problem).
However, upon the find of a new bug, the question is:
does all the research that use that software still 
result in the same conclusions?
To prevent authors chosing to hide bug reports, 
a code hosting website usually has a public place to report bugs,
to increase transparency in the handling of bug reports.

% \paragraph{Suggestions for knowledge management}

Here are multiple suggestions to make hosted code FAIR.
To make the hosted code findable, commonly a paper refers to its URL.
At the homepage of hosted code (e.g. a GitHub repository), 
there is no standardized metadata, to,
for example, link to the paper.
Using a popular code host ensures the code is easily accessible.
There is some interoperabily supplied by a version control manager,
such as in obtaining the history of the code.
The reusability of code is reasonably easy to assess, 
by using so-called build badges.
However, there is no guarantee that a build badge that claimes success,
actually is an honest signal (i.e. that code may not actually build),
nor are there standards for what 'success' entails.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Publishing a virtual environment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The most reproducible way of submitting the code of an experiment,
is by providing the code with all the (software) dependencies 
it needs installed in a virtual container.
This is close to the golden standard suggested by 
\cite{peng2011reproducible} 
\iffalse
(see also Figure \ref{fig:peng2011reproducible})
\fi
,
however, that article was written before virtualization existed.
Virtualization allows one to provide a standard environment,
that can be used on any other computer.
The best known examples of container software are Docker and Singularity.
Due to access rights, Singularity is the only viable option to run
an experiment on a 
high performance computing (HPC) environment (e.g. a computer cluster).

% \paragraph{Containers allow for runnable code, for longer periods of time}

Unlike English, code is fragile in standing the test of time.
Containers can alleviate this, as these can be created at a point
in time and then run later. Because the container is stand-alone,
all software that the code depends on remain in their current/old state.
As with hosted code, an experiment may not run with newer versions
of libraries anymore, but a containerized experiment can run regardless, 
if one refrains from updating (or only does so when there are there problems with fixing).

Ideally, to re-do an experiment, one would need a one-liner to a container,
for example, \verb|singularity run my_experiment.sif run|.

% \paragraph{Runnable code can precisely reproduce an experiment}

Containers allow a computation experiment to be highly reproducible:
given the same data, an experiment put into a container will give
the same results on different platforms, at least in theory.
In practice, differences may be observed when peripheral factors
are different, such as the random numbers as generated by an operating
system, or data that are downloaded from additional online sources.

% \paragraph{Runnable code allows others to re-use an experiment}

Containers allow a computation experiment to be highly re-usable,
as any scientist can work with it and tweak code.

% \paragraph{The problems with runnable code}

There are some problems with providing a container with a runnable container.
First, a container is several gigabytes and need to be stored somewhere
online. 
Ideally, for Singularity, this would be at the main container hosting
site called Syslabs. Using Syslabs is free upon registration, 
yet there is a limit of 15 Gb. Also, Sylabs does not allow much metadata to
be entered, such as the URL of the article, nor the URL of hosted code.
Also, journals do not request hosted code, nor runnable code.

% \paragraph{Suggestions for knowledge management}

Here are multiple suggestions to make containers with runnable code FAIR.
To make such containers findable, the most common 
environments (Syslabs and DockerHub) to upload containers must be indexed.
Uploading a container to those environments is, however, limited by
a restricted amount of free storage, with the possible consequence that
those containers are uploaded somewhere where they escape proper indexing.
Having containers uploaded at the existing websites ensures they are
accessible, interoperable and reusable.
One could argue however, that the scientific community need its own,
similar website to upload containers, as the metadata for these
sites are limited to free-text comments and tags (DockerHub)
or not metadata at all (Syslabs).

% \paragraph{Runnable code is the pinnacle of reproducible research}

When research truly needs to be reproducible, putting the code 
of an experiment into a container is a good solution, as it 
can stand the test of time better.
Creating such a container, however, requires more skill
that -as of today- is not rewarded,
partly as containers follow FAIR data principles only poorly.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sensitive data}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For a computational experiment to be reproducible,
an independent person should be able to
reproduce the same results.
The reproduce the same results, one needs the same
input data and the same code (and the same 
dependencies and environment).
When the input data are sensitive, however, and thus cannot be shared with
an independent researcher, one thus cannot reproduce the
experiment.

The solution for this problem is simple:
supply a simulated dataset with the code.
In the case of genetic epidemiology this would mean
simulated genotypes and associated phenotypes,
as can be done with the \verb|plinkr| R package \cite{plinkr}.
This solution, however, is known to all developer that follow
good practices when writing code, as public (i.e. simulated) 
datasets are needed for automatic testing of code.
One extra benefit of simulated data is that these can be used
as a benchmark, as slightly different analyses should give 
similar conclusions.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \paragraph{Definition of paradata}

% Reviewer 1: this section starts with a sentence that appears to undercut the whole theme of this chapter!
Code may or may not be paradata, depending on how the definition
is interpreted.
Here we repeat the definition of 'paradata' and discuss 
its constituents.
This paper defined paradata as 'data about the collecting of the data'.
This implies that (1) code must be seen as data.
This paper argues, that code is data in the form of text spread
over one or more files with useful measurable properties.
(2) downloading raw data and doing calculations must be seen as collecting.
This paper argues that downloading raw datas and doing calculations, 
such as a T-test,
does describe how the bits and pieces of an end result are collected.
(3) the results of an experiment must be seen as data.
This paper argues that an experimental results is data, 
as it can be measured and can be used as the raw data of a next experiment.

% \paragraph{The drawbacks of publishing code}

Publishing code may be disadvantageous for an author.
For science, code should be published, 
this allows reproducible research 
(again, see \cite{haibe2020importance} for a tragic example).
For an author, publishing code alongside an experiment opens up
the possibily to receive questions regarding that code.
Note, however, that not publishing code may put 
oneself in the focus of attention
and -after much effect by others reproducing an incorrect result-
at the cost of a scientific career \cite{baggerly2009deriving}.

% \paragraph{The drawbacks of publishing version-controlled code}

Is it worth it to publish version-controlled code?
For an author, 
there is additional training involved, and also here,
publishing code alongside an experiment opens up
the possibily to receive questions regarding that code,
as well as other interactions, including helpful contributions.

% \paragraph{The drawbacks of publishing a running version of code}

Is it worth it to archive running versions of code?
For an author, 
there is additional training involved.
There is no FAIR infrastructure for Singularity containers.

% \paragraph{Still need the same data to do a reproducible experiment}

% \paragraph{Recommendations}

Being able to re-do an experiment is a core principle of the scientific method.
Publishing only a paper about a computational experiment is not enough,
as the results are too likely to mismatch that English description.
Journal should make it mandatory for authors
to publish their code alongside a computational experiment.
Authors should follow the FAIR principes for their code as well,
as can be done using the infrastructure as supplied by, 
for example, GitHub and GitLab, opening up new angles in
metascience regarding computational experiments.
Knowledge managers should create the infrastructure for the preservation
of runnable experiments, to allow scientist to upload a Singularity
container, so these are as well following the FAIR principles.

\iffalse
\rowcolors{2}{gray!10}{gray!40}
\begin{table}[h]
  \begin{tabular}{|p{2cm}|l|}
    \hline
    \textbf{Type of code} & \textbf{Recommendation} \\
    \hline
    No code       & Disallow papers that do not supply code publicly \\
    \hline
    Raw code      & Don't publish raw code as text, host it on a code hosting website \\
    \hline
    Hosted code   & Use a standarized badge for build status \\
                  & Use a standarized badge for code coverage \\
                  & Standardize to link between paper and code host \\
    \hline
    Runnable code & Allow to upload containers without limits \\
                  & Website to host containers must allow for annotation \\
                  & Use a standarized badge for the container to be functioning  \\
                  & Standarize to link between container, paper and code repository \\
    \hline
  \end{tabular}
  \caption{Recommendations described in this paper}
  \label{tab:recommendations}
\end{table}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This paper started with some suggestions to 
make paradata useful for data re(use):
paradata should be comprehensive, comprehensively documented
and friendly to computers \cite{huvila2022improving}.
When applying these general recomendations to code, 
this list can be phrased more precisely:
code should be comprehensive in supplying 
automatically generated metadata (such as commit history and code coverage).
The documentation should be as extensive as recommended by the 
software development literature. To be computer friendly,
code should be able to run on at least one independent entity,
such as a GitHub Actions server or from a Singularity container.


Code has additional useful information, similar to confidence intervals,
that allow a reader to gauge how much one trusts the results.
The more of the best practices are followed, 
the more trustworthy are the results.
The most important best practices discussed in this paper are
automatic testing, having a high code coverage and code
of low (cyclomatic) complexity.
In academia, to uncover the truth, code correctness is essential,
similar to cell biologists working sterile to not contaminate their
cell cultures.
These best practices are vital for a computational biologist.

For research to be reproducible, one ideally has access to
both the data used and the code.
In some fields, such as genetic epidemiology, the data are
sensitive, hence cannot be released,
yet there are methods being devised to run code on sensitive
data with assured privacy \cite{zhang2016review,azencott2018machine}.
Additionally, it follows software development's best practices 
(especially the practice to test code automatically) 
to release a simulated/public dataset, with
the additional benefit that this dataset can be used for comparisons.

Code is harder to preserve than an English text
and preserving code is rarely done \cite{barnes2010publish}.
Although code is the primary actor in computational experiments,
there is no incentive to submit code alongside a publication.
Most academic journal do not require authors to submit their code,
nor is the submitted code peer reviewed, 
rOpenSci \cite{ram2018community} being the pleasant exception.

Code used in academic research complies badly with FAIR principles,
where unpublished code is the worst offender.
However, any idealistic researcher does not have the
tools to following FAIR principles in an exemplary way:
there are no standards in how a scholarly article
refers to academic code (i.e. in a machine-friendly way).
Creating a (Singularity) container is the best a researcher
can do to ensure his/her code is reusable,
yet, there are no incentives to make code accessible, interoperable
or re-usable, with standarized metadata attributes being absent.

% \paragraph{Final word}

The world of science would be a more open, humble, trustworthy, truthful
and helpful would the code that accompanies a scientific paper
be treated like a first class citizen. As doing so in an exemplary way
is yet to be rewarded, hence it has to be the idealististic scientists
to wage this battle. I feel the truth and science are worth fighting for
and I hope this paper helps others to join.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data Accessibility}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This article and its metadata can be found at 
\begin{sloppypar}\url{https://github.com/richelbilderbeek/chapter_paradata}\end{sloppypar}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Vancouver style
\bibliographystyle{unsrtnat}
\bibliography{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\section{Supplementary materials}

% Figures start from one and are prepended with an S
\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{figure}{0}

% Tables start from one and are prepended with an S
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{0}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{This paper}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This paper has been produced following all recommendations in it:
it's \latex code is hosted on GitHub 
at \url{https://github.com/richelbilderbeek/chapter_paradata}.
Due this, one can, among others, see the complete version history of this paper.
This alone could allow research to be done on, for example,
the effect of reviewers' feedback on a first manuscript.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Funding}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This chapter has not been supported by funding.

% Duran et al., grounds for trust
% [A] process is epistemically opaque relative to a cognitive agent X at time t
% just in case X does not know at t all of the epistemically relevant elements of
% the process (Humphreys 2009, 618)
% 
% On Computational reliability
% 
% (CR) if Ss believing p at t results from m, then Ss belief in p at t is justified.
% where S is a cognitive agent, p is any truth-valued proposition related to the
% results of a computer simulation, t is any given time, and m is a reliable com
% puter simulation.
%
%
% 4Sources for Computational Reliabilism
%
% 1. Verification and validation methods
% 2. Robustness analysis for computer simulations
% 3. A history of (un)successful implementations
% 4. Expert knowledge


